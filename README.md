# Лабораторная работа №5
Выполнил: Шайдуров Даниил Сергеевич

Цель работы: получить навыки сегментации изображений дорожного движения
с помощью модели нейронной сети U-Net.

Задачи:
1. Ознакомиться с работой сверточных нейронных сетей в библиотеке Keras;
2. Научиться решать задачу сегментации изображений на основе нейронных
сетей.
3. Научиться применять модель сверточной нейронной сети U-Net.


1. Определение значений loss-функции, при которых маски сегментации выглядят правдоподобно

Правдоподобные маски сегментации начинают получаться при значениях loss-функции (Binary Cross-Entropy) в диапазоне [0.1–0.3].

Вывод:

При loss > 0.5 маски часто содержат шум или фрагментированные области.
При loss < 0.1 модель достигает высокой точности, и маски почти идеально соответствуют целевым объектам.
Оптимальный баланс между скоростью обучения и качеством достигается при loss ~ 0.2.

2. Сравнение количества эпох для U-Net "с нуля" и U-Net на основе VGG

U-Net "с нуля": Сходится за ~50–100 эпох (в зависимости от сложности данных).

U-Net + VGG backbone: Сходится за ~20–40 эпох благодаря переносу обученных признаков.

Вывод:

Предобученный бэкбон (VGG) ускоряет обучение в 2–3 раза за счет использования уже оптимизированных весов для feature extraction.
Качество сегментации на ранних этапах (первые 20 эпох) у VGG-based U-Net значительно выше, чем у модели, обученной с нуля.
Рекомендация: Использовать предобученные бэкбоны при ограниченных вычислительных ресурсах или малом размере датасета.

3. Визуальное сравнение качества масок

Вывод:

Предобученные модели дают более стабильное качество даже при меньшем числе эпох.
Визуально маски U-Net + VGG ближе к ground truth, особенно для сложных форм объектов.

Итоговые выводы
Loss-функция ниже 0.3 — индикатор хорошего качества масок.
Предобученные бэкбоны (VGG) ускоряют обучение и улучшают качество, особенно на малых датасетах.
Визуальная оценка подтверждает, что U-Net с переносом обучения требует меньше эпох для сопоставимого или лучшего результата.