# Лабораторная работа №5
Выполнил: Шайдуров Даниил Сергеевич

Цель работы: получить навыки сегментации изображений дорожного движения
с помощью модели нейронной сети U-Net.

Задачи:
1. Ознакомиться с работой сверточных нейронных сетей в библиотеке Keras;
2. Научиться решать задачу сегментации изображений на основе нейронных
сетей.
3. Научиться применять модель сверточной нейронной сети U-Net.

## 1. Определение значений loss-функции, при которых маски сегментации выглядят правдоподобно

Базовая модель u-net без бэкбона обучалась на 60 эпохах. Удовлетворительного результата так и не получилось достигнуть 
по причине простой архитектуру нейросети и небольшого объема датасета. Минимальный лосс на валидации 1,4. 
Ниже представлены скрины на 14 и 60 эпохе обучения. 

Эпоха 14
![images](https://github.com/DaniilShd/NN_lab_5/blob/main/result_image/unet/epoch_14_comparison.png)

Эпоха 60 
![images](https://github.com/DaniilShd/NN_lab_5/blob/main/result_image/unet/epoch_59_comparison.png)

Значения лосс-функции на тренировочных и валидационных данных. 
![images](https://github.com/DaniilShd/NN_lab_5/blob/main/result_image/unet/unet.png)


U-net спроектированная на базе предобученной модели vgg показала результата лучше. 

Правдоподобные маски сегментации начинают получаться при значениях loss-функции (Binary Cross-Entropy) в диапазоне [0.1–0.3].

Эпоха 14
![images](https://github.com/DaniilShd/NN_lab_5/blob/main/result_image/unet/epoch_14_comparison.png)

Эпоха 60 
![images](https://github.com/DaniilShd/NN_lab_5/blob/main/result_image/unet/epoch_59_comparison.png)

Вывод:

При loss > 1.0 маски часто содержат шум или фрагментированные области.
При loss < 0.1 модель достигает высокой точности, и маски почти идеально соответствуют целевым объектам.
Оптимальный баланс между скоростью обучения и качеством достигается при loss ~ 0.2.

## 2. Сравнение количества эпох для U-Net "с нуля" и U-Net на основе VGG

U-Net "с нуля": Сходится за ~50–100 эпох (в зависимости от сложности данных).

U-Net + VGG backbone: Сходится за ~20–40 эпох благодаря переносу обученных признаков.

Вывод:

Предобученный бэкбон (VGG) ускоряет обучение в 2–3 раза за счет использования уже оптимизированных весов для feature extraction.
Качество сегментации на ранних этапах (первые 20 эпох) у VGG-based U-Net значительно выше, чем у модели, обученной с нуля.
Рекомендация: Использовать предобученные бэкбоны при ограниченных вычислительных ресурсах или малом размере датасета.

## 3. Визуальное сравнение качества масок

Вывод:

Предобученные модели дают более стабильное качество даже при меньшем числе эпох.
Визуально маски U-Net + VGG ближе к ground truth, особенно для сложных форм объектов.

## Итоговые выводы
Loss-функция ниже 0.3 — индикатор хорошего качества масок.
Предобученные бэкбоны (VGG) ускоряют обучение и улучшают качество, особенно на малых датасетах.
Визуальная оценка подтверждает, что U-Net с переносом обучения требует меньше эпох для сопоставимого или лучшего результата.